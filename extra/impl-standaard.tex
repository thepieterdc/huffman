\section{Standaard Huffmancoding}

Bij het \emph{Standaard Huffmancoding}-algoritme heb ik de meeste optimalisaties toegepast. Dit algoritme leent zich, van alle vijf de algoritmes, hier het beste toe, omdat de volledige tekst moet worden ingelezen alvorens er gecodeerd kan worden. Dit zorgt ervoor dat er allerlei informatie over de tekst kan worden vergaard, zoals bijvoorbeeld de randomness. Voor er gestart wordt met encoderen of decoderen wordt eerst bepaald of de tekst \texttt{random} is. Indien dit het geval is, wordt een alternatief encodeer- en decodeeralgoritme gebruikt, om hogere snelheden te kunnen bereiken. Een tekst kwalificeert als \texttt{random} als alle 256 extended ascii tekens er in quasi dezelfde frequentie in voorkomen. Het gevolg hiervan is dat elk karakter een code van lengte 8 bits heeft.

\subsection{Encoder}

\subsubsection{Gewone tekst}
	- regular: dictionary met structs
	
\subsubsection{Random data}
	- random: map want 8 bits codes
	
\subsection{Decoder}

\subsubsection{Gewone tekst}
	- regular: lookup tables

\subsubsection{Random data}
	- random: map want 8 bits codes = 8 bits karakters

\subsection{Alternatief}
Tijdens het programmeren van de \texttt{random} encoder en decoder, stuitte ik op een interessante vaststelling. Dit heb ik echter niet in de praktijk uitgewerkt, omdat het geen verband meer had met Huffmancoding, maar ik zal het wel hier bespreken. Eerder werd reeds vermeld dat in een random tekst elk karakter een code van lengte 8 bits heeft, even lang als de 1 byte waarmee het karakter voorgesteld wordt. Een alternatief, veel sneller codeeralgoritme zou dus onderstaande pseudo C-code kunnen zijn. Het is echter effici\"enter om de tekst dan niet te encoderen, aangezien de boom en \emph{ascii}-tabel nu enkel nog extra overhead zijn.