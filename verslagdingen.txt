- Bytes worden gebruikt als indexen

- uint256 gmaakt maar weggegooid want (enkel in standaard gebruikt)
    zeg dat in pricipe bij rest ook niet zou kunnen want 10tb hdd maar serverdistributie
    worst case: 256bits code
        -> fibonacci verdeeld -- CHECK DIT NOG EENS MET EEN VOORBEELD
            -> 256 bits = 256e fibo getal = complete zever
            -> 64 bits = 64e fibo getal = 10tb -> nog steeds teveel
            -> 32 bits = 32e fibo getal = 2mb -> veel te weinig -> 64 bits is genoeg
                -> 256 structuur mag weg


- Nodes apart opgeslagen in tree zodat O(1) access voor bvb standaard encoder

- Bit input/output stream
    buffer zodat op einde pas effectief geprint moet worden (veel sneller)
    vaste buffergrootte zodat geheugengebruik niet gigantisch zou worden

- Fibo heap gebruikt om boom op te bouwen want tabel op https://en.wikipedia.org/wiki/Priority_queue
    (of zeggen dat het niet de moeite was want O(256 en enkel in standaard)

- Ordernummers bij adaptive omgekeerd zodat ik ze nooit moet incrementeren

- putc bij printen gbruikt aangezien dat intern buffert

- twopass slechtste want gewichten doorsturen die 4 bytes nemen

- windowsize: (inputs verticaal: 10k, 25k, 100k)
    d=500   d = 750     d=1OOO  d = 1250    d= 1500 d=infty
    50823   50456       50257   50248       50256   50440
    129083  128202      127900  128045      128375  129120
    526736  523541      521102  520248      520706  519561
avg:235547  234066      233086  232847      233112  2330404
        -> 1250 wint (d betekent windowsize en avg is average textlengte)

- random data heeft alle paden lengte 8 -> kan onmiddellijk geprint worden zonder buffer
ook in decoder rekening mee gehouden
beklemtonen dat er eigenlijk vanalles gedaan is om het enorm snel te maken voor random data

- unlocked_io want sneller -> file locks

- outputbuffer size testen met mooie grafieken enzo

"als je totale random data met standaard zou encoden kan je gewoon zeggen dat de code == de ascii waarde"

decoding standaard via lookuptable:
    kijk hoeveel bits er nog gelezen kunnen worden in de huidige byte van inputreader
    maak tables van 1->x (x = min(8, langste_code_lengte))
    zoek op in grootste lookup table
    indien leaf -> print
    indien node -> ga vanaf daar verder met standaard manier

-findswap: zoek alle nodes hoger in de boom met hetzelfde gewicht als deze node
    -> O(n) met n = het aantal nodes van zelfde gewicht -> nooit echt heel hoog op normale teksten want onmogelijk dat elke letter exact evenveel voorkomt

sliding zelfde principe ^

- codes op andere plaatsen ook door 64bit voorgesteld want file moet ook op disk passen dus 10tb was genoeg

- swaps in uint64 stuff
    http://www.yolinux.com/TUTORIALS/Endian-Byte-Order.html